# Manifesto do spark-aplication
apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: spark-test-exemple
  namespace: processing
spec:
  type: Python
  pythonVersion: "3"
  mode: cluster
  image: igorformiga/spark-kubernets:1.0
  imagePullPolicy: Always
  mainApplicationFile: "local:///app/spark-app.py"
  sparkConf:
    spark.hadoop.fs.s3a.endpoint: "http://datalake-hl.deepstore:9000"
    spark.hadoop.fs.s3a.path.style.access: "true"
    spark.hadoop.fs.s3a.impl: "org.apache.hadoop.fs.s3a.S3AFileSystem"
    spark.sql.shuffle.partitions: "10"
    spark.default.parallelism: "8"
    spark.memory.fraction: "0.6"
    spark.memory.storageFraction: "0.3"
    spark.hadoop.fs.s3a.connection.maximum: "100"
    spark.hadoop.fs.s3a.fast.upload: "true"
    spark.hadoop.fs.s3a.threads.max: "20"
    spark.metrics.conf: "/etc/metrics/conf/metrics.properties"
  arguments:
    - "bronze"
    - "owshq-shadow-traffic-uber-eats/kafka/orders"
    - "owshq-shadow-traffic-uber-eats/mysql/products"
    - "owshq-shadow-traffic-uber-eats/mongodb/items"
    - "s3a://owshq-shadow-traffic-uber-eats/parquet"
  sparkVersion: 3.5.3
  timeToLiveSeconds: 30
  driver:
    cores: 1
    memory: 1024m
    serviceAccount: spark-operator-spark
    envSecretKeyRefs:
      AWS_ACCESS_KEY_ID:
        name: minio-spark-secret
        key: AWS_ACCESS_KEY_ID
      AWS_SECRET_ACCESS_KEY:
        name: minio-spark-secret
        key: AWS_SECRET_ACCESS_KEY
  executor:
    instances: 2
    cores: 2
    memory: 1024m
    envSecretKeyRefs:
      AWS_ACCESS_KEY_ID:
        name: minio-spark-secret
        key: AWS_ACCESS_KEY_ID
      AWS_SECRET_ACCESS_KEY:
        name: minio-spark-secret
        key: AWS_SECRET_ACCESS_KEY
  monitoring:
    exposeDriverMetrics: true
    exposeExecutorMetrics: true
    prometheus:
      jmxExporterJar: /prometheus/jmx_prometheus_javaagent-0.11.0.jar
      port: 8090